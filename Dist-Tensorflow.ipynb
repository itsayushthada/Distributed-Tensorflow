{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PTask.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/itsayushthada/Distributed-Tensorflow/blob/master/Dist-Tensorflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "X040FqfXUuQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48a168ce-9c37-4e57-8b09-61c11dfae874"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.nn import conv2d, relu, max_pool, dropout\n",
        "from tensorflow.layers import dense, batch_normalization, flatten\n",
        "from tensorflow.initializers import he_normal\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nNFBcmAMUvhA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFVLusdmUzYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "87d86042-c2e5-40c9-adc8-89b941f1ec23"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training Set Size: {}\".format(x_train.shape))\n",
        "print(\"Test Set Size: {}\".format(x_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Size: (50000, 32, 32, 3)\n",
            "Test Set Size: (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RkeF7BcIVF6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(x, num_of_class):\n",
        "    b = np.zeros((x.shape[0], num_of_class))\n",
        "    b[np.arange(x.shape[0]), x.reshape((-1, ))] = 1\n",
        "    return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AYxP-jwQVIOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x, is_img=True):\n",
        "    if is_img:\n",
        "        return x/255\n",
        "    else:\n",
        "        return x / np.max(x[x.shape[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXNbBu-eVkPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_batch(x_train, y_train, batch_size):\n",
        "    indices = np.random.randint(0, y_train.shape[0], [batch_size,])\n",
        "    x_data = np.array(x_train[np.random.randint(0, y_train.shape[0], [batch_size,]), :,:,:])\n",
        "    y_data = np.array(y_train[np.random.randint(0, y_train.shape[0], [batch_size,]), :])\n",
        "    return normalize(x_data), one_hot(y_data, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQZylTqWVmcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#HYPER_PARAMETERS\n",
        "batch_size=32\n",
        "epochs = 10\n",
        "keep_probability = 0.7\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bs3u-kwLVopc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#Inputs\n",
        "x = tf.placeholder(dtype=tf.float16, shape=(None, 32, 32, 3), name=\"InputX\")\n",
        "y = tf.placeholder(dtype=tf.float16, shape=(None, 10), name=\"InputY\")\n",
        "#keep_prob = tf.placeholder(dtype=tf.float16, name=\"DropOutRate\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Re-vlS-Vqoq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Randomly Initilized Variables\n",
        "\n",
        "conv1_filter = tf.Variable(tf.truncated_normal(shape=[3,3,3,64], dtype=tf.float16, seed=12))\n",
        "conv2_filter = tf.Variable(tf.truncated_normal(shape=[3,3,64,128], dtype=tf.float16, seed=12))\n",
        "conv3_filter = tf.Variable(tf.truncated_normal(shape=[3,3,128,256], dtype=tf.float16, seed=12))\n",
        "conv4_filter = tf.Variable(tf.truncated_normal(shape=[3,3,256,512], dtype=tf.float16, seed=12))\n",
        "#conv5_filter = tf.Variable(tf.truncated_normal(shape=[1,1,512,1], dtype=tf.float16, seed=12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k00RVcgMVszd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Architecture\n",
        "\n",
        "def model(x):\n",
        "\n",
        "    with tf.name_scope(name=\"Layer1\"):\n",
        "        conv1 = conv2d(x, filter=conv1_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv1 = relu(conv1)\n",
        "        pool1 = max_pool(actv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano1 = batch_normalization(pool1)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer2\"):\n",
        "        conv2 = conv2d(bano1, filter=conv2_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv2 = relu(conv2)\n",
        "        pool2 = max_pool(actv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano2 = batch_normalization(pool2)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer3\"):\n",
        "        conv3 = conv2d(bano2, filter=conv3_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv3 = relu(conv3)\n",
        "        pool3 = max_pool(actv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano3 = batch_normalization(pool3)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer4\"):\n",
        "        conv4 = conv2d(bano3, filter=conv4_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv4 = relu(conv4)\n",
        "        pool4 = max_pool(actv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano4 = batch_normalization(pool4)\n",
        "\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name=\"Layer5\"):\n",
        "        conv5 = conv2d(bano4, filter=conv5_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv5 = relu(conv5)\n",
        "        bano5 = batch_normalization(actv5)\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.name_scope(name=\"Layer6\"): \n",
        "        reshape1 = flatten(bano4)\n",
        "        \n",
        "    with tf.name_scope(name=\"Layer7\"): \n",
        "        dense1 = dense(reshape1, 512)\n",
        "        #drop1 = dropout(dense1, keep_prob)\n",
        "        actv6 = relu(dense1)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer8\"): \n",
        "        dense2 = dense(actv6, 128)\n",
        "        #drop2 = dropout(dense2, keep_prob)\n",
        "        actv7 = relu(dense2)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer9\"): \n",
        "        dense3 = dense(actv7, 10)\n",
        "        \n",
        "    return dense3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4E4MHcHTVwgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Unnormalized Log Probabilities\n",
        "\n",
        "pred = model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQLD2arvVyp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loss & Optimizer\n",
        "\n",
        "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=pred))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYo-LE_pV0xu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float16), name=\"Accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n38HNJ88V27m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        n_batches = 5\n",
        "        for batch in range(n_batches):\n",
        "            x_data, y_data = sample_batch(x_train, y_train, batch_size)   \n",
        "            loss = sess.run(optimizer, feed_dict = \n",
        "                     {\n",
        "                        x: x_data,\n",
        "                        y: y_data,\n",
        "                        #keep_prob: keep_probability\n",
        "                     }\n",
        "                    )\n",
        "            \n",
        "            acc = sess.run(accuracy, feed_dict = \n",
        "                     {\n",
        "                        x: x_data,\n",
        "                        y: y_data,\n",
        "                        #keep_prob: keep_probability\n",
        "                     }\n",
        "                    )\n",
        "        print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IwuZhY0RV5Ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}