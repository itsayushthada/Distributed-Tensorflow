{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PTask.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/itsayushthada/Distributed-Tensorflow/blob/master/DistTensorflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "X040FqfXUuQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a97f89bb-5a75-4649-c221-5de4f35a0247"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.nn import conv2d, relu, max_pool, dropout\n",
        "from tensorflow.layers import dense, batch_normalization, flatten\n",
        "from tensorflow.initializers import he_normal\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nNFBcmAMUvhA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFVLusdmUzYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "457ab7a7-adf3-4e49-b9f9-17f892cbb573"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training Set Size: {}\".format(x_train.shape))\n",
        "print(\"Test Set Size: {}\".format(x_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Size: (50000, 32, 32, 3)\n",
            "Test Set Size: (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RkeF7BcIVF6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(x, num_of_class):\n",
        "    b = np.zeros((x.shape[0], num_of_class))\n",
        "    b[np.arange(x.shape[0]), x.reshape((-1, ))] = 1\n",
        "    return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AYxP-jwQVIOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x, is_img=True):\n",
        "    if is_img:\n",
        "        return x/255\n",
        "    else:\n",
        "        return x / np.max(x[x.shape[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXNbBu-eVkPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_batch(x_train, y_train, batch_size):\n",
        "    indices = np.random.randint(0, y_train.shape[0], [batch_size,])\n",
        "    x_data = np.array(x_train[np.random.randint(0, y_train.shape[0], [batch_size,]), :,:,:])\n",
        "    y_data = np.array(y_train[np.random.randint(0, y_train.shape[0], [batch_size,]), :])\n",
        "    return normalize(x_data), one_hot(y_data, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQZylTqWVmcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#HYPER_PARAMETERS\n",
        "batch_size=32\n",
        "epochs = 10\n",
        "keep_probability = 0.7\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bs3u-kwLVopc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#Inputs\n",
        "x = tf.placeholder(dtype=tf.float16, shape=(None, 32, 32, 3), name=\"InputX\")\n",
        "y = tf.placeholder(dtype=tf.float16, shape=(None, 10), name=\"InputY\")\n",
        "keep_prob = tf.placeholder(dtype=tf.float16, name=\"DropOutRate\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Re-vlS-Vqoq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Randomly Initilized Variables\n",
        "\n",
        "conv1_filter = tf.Variable(tf.truncated_normal(shape=[3,3,3,64], dtype=tf.float16, seed=12))\n",
        "conv2_filter = tf.Variable(tf.truncated_normal(shape=[3,3,64,128], dtype=tf.float16, seed=12))\n",
        "conv3_filter = tf.Variable(tf.truncated_normal(shape=[3,3,128,256], dtype=tf.float16, seed=12))\n",
        "conv4_filter = tf.Variable(tf.truncated_normal(shape=[3,3,256,512], dtype=tf.float16, seed=12))\n",
        "conv5_filter = tf.Variable(tf.truncated_normal(shape=[1,1,512,1], dtype=tf.float16, seed=12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k00RVcgMVszd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Architecture\n",
        "\n",
        "def model(x, keep_prob):\n",
        "    with tf.name_scope(name=\"Layer1\"):\n",
        "        conv1 = conv2d(x, filter=conv1_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv1 = relu(conv1)\n",
        "        pool1 = max_pool(actv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano1 = batch_normalization(pool1)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer2\"):\n",
        "        conv2 = conv2d(bano1, filter=conv2_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv2 = relu(conv2)\n",
        "        pool2 = max_pool(actv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano2 = batch_normalization(pool2)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer3\"):\n",
        "        conv3 = conv2d(bano2, filter=conv3_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv3 = relu(conv3)\n",
        "        pool3 = max_pool(actv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano3 = batch_normalization(pool3)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer4\"):\n",
        "        conv4 = conv2d(bano3, filter=conv4_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv4 = relu(conv4)\n",
        "        pool4 = max_pool(actv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "        bano4 = batch_normalization(pool4)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer5\"):\n",
        "        conv5 = conv2d(bano4, filter=conv5_filter, strides=[1,1,1,1], padding=\"SAME\")\n",
        "        actv5 = relu(conv5)\n",
        "        bano5 = batch_normalization(actv5)\n",
        "    \n",
        "    with tf.name_scope(name=\"Layer6\"): \n",
        "        reshape1 = flatten(bano5)\n",
        "        \n",
        "    with tf.name_scope(name=\"Layer7\"): \n",
        "        dense1 = dense(reshape1, 1024)\n",
        "        drop1 = dropout(dense1, rate=keep_prob)\n",
        "        actv6 = relu(drop1)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer8\"): \n",
        "        dense2 = dense(actv6, 128)\n",
        "        drop2 = dropout(dense2, rate=keep_prob)\n",
        "        actv7 = relu(drop2)\n",
        "\n",
        "    with tf.name_scope(name=\"Layer9\"): \n",
        "        dense3 = dense(actv7, 10)\n",
        "        \n",
        "    return dense3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4E4MHcHTVwgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Unnormalized Log Probabilities\n",
        "\n",
        "pred = model(x, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQLD2arvVyp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loss & Optimizer\n",
        "\n",
        "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=pred))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYo-LE_pV0xu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float16), name=\"Accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n38HNJ88V27m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1192
        },
        "outputId": "f87a9ebd-6098-4b51-ac0a-53868ce1e5e1"
      },
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        n_batches = 5\n",
        "        for batch in range(n_batches):\n",
        "            x_data, y_data = sample_batch(x_train, y_train, batch_size)   \n",
        "            loss = sess.run(optimizer, feed_dict = \n",
        "                     {\n",
        "                        x: x_data,\n",
        "                        y: y_data,\n",
        "                        keep_prob: keep_probability\n",
        "                     }\n",
        "                    )\n",
        "            \n",
        "            accuracy = sess.run(accuracy, feed_dict = \n",
        "                     {\n",
        "                        x: x_data,\n",
        "                        y: y_data,\n",
        "                        keep_prob: keep_probability\n",
        "                     }\n",
        "                    )\n",
        "        print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    283\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 284\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    285\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3576\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3577\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can not convert a float16 into a Tensor or Operation.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-23e502f60a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                      }\n\u001b[1;32m     23\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1095\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    286\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    287\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    289\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
            "\u001b[0;31mTypeError\u001b[0m: Fetch argument 0.0625 has invalid type <class 'numpy.float16'>, must be a string or Tensor. (Can not convert a float16 into a Tensor or Operation.)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "IwuZhY0RV5Ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}