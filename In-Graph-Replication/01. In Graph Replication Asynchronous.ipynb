{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Graph Replication Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (60000, 28, 28)\n",
      "Test Set: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set: {}\".format(x_train.shape))\n",
    "print(\"Test Set: {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (60000,)\n",
      "Test Set: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set: {}\".format(y_train.shape))\n",
    "print(\"Test Set: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = tf.train.ClusterSpec(\n",
    "    {\n",
    "        \"ps\": [\"172.17.0.1:2222\"],\n",
    "        \"worker\": [\"172.17.0.2:2223\",\n",
    "                   \"172.17.0.3:2224\",\n",
    "                   \"172.17.0.4:2225\",\n",
    "                   \"172.17.0.5:2226\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "if y_train.shape[1] != 10:\n",
    "    y_train = y_train[:,0]\n",
    "    y_test = y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (60000, 10)\n",
      "Test Set: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set: {}\".format(y_train.shape))\n",
    "print(\"Test Set: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28], name=\"x\")\n",
    "y = tf.placeholder(tf.int8, shape=[None, 10], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Graph on Parameter Server 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/job:ps/task:0\"):  \n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "                              inputs=input_layer,\n",
    "                              filters=32,\n",
    "                              kernel_size=[5, 5],\n",
    "                              padding=\"same\",\n",
    "                              activation=tf.nn.relu\n",
    "                            )\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "                                    inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2\n",
    "                                    )\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "                              inputs=pool1,\n",
    "                              filters=64,\n",
    "                              kernel_size=[5, 5],\n",
    "                              padding=\"same\",\n",
    "                              activation=tf.nn.relu\n",
    "                            )\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "                                    inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2\n",
    "                                    )\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(\n",
    "                            tensor=pool2, \n",
    "                            shape=[-1, 7 * 7 * 64]\n",
    "                            )\n",
    "\n",
    "    dense = tf.layers.dense(\n",
    "                            inputs=pool2_flat, \n",
    "                            units=1024, \n",
    "                            activation=tf.nn.relu\n",
    "                            )\n",
    "\n",
    "    dropout = tf.layers.dropout(\n",
    "                                inputs=dense, \n",
    "                                rate=0.4, \n",
    "                                )\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(\n",
    "                            inputs=dropout, \n",
    "                            units=10\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_WORKERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Graph on Worker Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS = {}\n",
    "\n",
    "for i in range(NO_OF_WORKERS):\n",
    "    with tf.device(\"/job:worker/task:{}\".format(i)): \n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=tf.argmax(y, axis=1), logits=logits)\n",
    "\n",
    "\n",
    "        # Configure the Training Op (for TRAIN mode)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "                                    loss=loss,\n",
    "                                    global_step=tf.train.get_global_step()\n",
    "                                  )\n",
    "\n",
    "\n",
    "        # Add evaluation metrics (for EVAL mode)\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        OUTPUTS[i] = [loss, correct_pred, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6000\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:    0   Loss:2.288923   Val_Acc:12.500%   Test_Acc:10.360%\n",
      "Epochs:  100   Loss:2.287751   Val_Acc:18.750%   Test_Acc:18.590%\n",
      "Epochs:  200   Loss:2.254906   Val_Acc:12.500%   Test_Acc:19.790%\n",
      "Epochs:  300   Loss:2.265726   Val_Acc:31.250%   Test_Acc:32.460%\n",
      "Epochs:  400   Loss:2.171551   Val_Acc:62.500%   Test_Acc:34.600%\n",
      "Epochs:  500   Loss:2.251521   Val_Acc:18.750%   Test_Acc:42.720%\n",
      "Epochs:  600   Loss:2.168793   Val_Acc:37.500%   Test_Acc:45.590%\n",
      "Epochs:  700   Loss:2.086233   Val_Acc:62.500%   Test_Acc:56.600%\n",
      "Epochs:  800   Loss:2.075069   Val_Acc:50.000%   Test_Acc:63.570%\n",
      "Epochs:  900   Loss:1.883248   Val_Acc:62.500%   Test_Acc:66.720%\n",
      "Epochs: 1000   Loss:1.811375   Val_Acc:75.000%   Test_Acc:72.340%\n",
      "Epochs: 1100   Loss:1.411565   Val_Acc:93.750%   Test_Acc:72.620%\n",
      "Epochs: 1200   Loss:1.460059   Val_Acc:62.500%   Test_Acc:73.610%\n",
      "Epochs: 1300   Loss:1.307693   Val_Acc:75.000%   Test_Acc:77.420%\n",
      "Epochs: 1400   Loss:1.025935   Val_Acc:87.500%   Test_Acc:78.200%\n",
      "Epochs: 1500   Loss:0.877257   Val_Acc:87.500%   Test_Acc:79.820%\n",
      "Epochs: 1600   Loss:0.979039   Val_Acc:75.000%   Test_Acc:82.660%\n",
      "Epochs: 1700   Loss:0.810631   Val_Acc:87.500%   Test_Acc:82.910%\n",
      "Epochs: 1800   Loss:0.920117   Val_Acc:62.500%   Test_Acc:84.670%\n",
      "Epochs: 1900   Loss:0.599449   Val_Acc:75.000%   Test_Acc:85.100%\n",
      "Epochs: 2000   Loss:0.381150   Val_Acc:93.750%   Test_Acc:85.750%\n",
      "Epochs: 2100   Loss:0.524026   Val_Acc:81.250%   Test_Acc:86.480%\n",
      "Epochs: 2200   Loss:0.566816   Val_Acc:87.500%   Test_Acc:86.960%\n",
      "Epochs: 2300   Loss:0.298017   Val_Acc:100.000%   Test_Acc:87.990%\n",
      "Epochs: 2400   Loss:0.304182   Val_Acc:93.750%   Test_Acc:87.990%\n",
      "Epochs: 2500   Loss:0.416609   Val_Acc:87.500%   Test_Acc:88.630%\n",
      "Epochs: 2600   Loss:0.212383   Val_Acc:93.750%   Test_Acc:88.480%\n",
      "Epochs: 2700   Loss:0.277377   Val_Acc:93.750%   Test_Acc:88.840%\n",
      "Epochs: 2800   Loss:0.185204   Val_Acc:93.750%   Test_Acc:89.350%\n",
      "Epochs: 2900   Loss:0.280558   Val_Acc:87.500%   Test_Acc:89.500%\n",
      "Epochs: 3000   Loss:0.232818   Val_Acc:93.750%   Test_Acc:89.520%\n",
      "Epochs: 3100   Loss:0.279522   Val_Acc:93.750%   Test_Acc:90.010%\n",
      "Epochs: 3200   Loss:0.092858   Val_Acc:100.000%   Test_Acc:90.270%\n",
      "Epochs: 3300   Loss:0.158664   Val_Acc:100.000%   Test_Acc:90.600%\n",
      "Epochs: 3400   Loss:0.239245   Val_Acc:93.750%   Test_Acc:90.270%\n",
      "Epochs: 3500   Loss:0.592282   Val_Acc:87.500%   Test_Acc:90.520%\n",
      "Epochs: 3600   Loss:0.806960   Val_Acc:75.000%   Test_Acc:90.450%\n",
      "Epochs: 3700   Loss:0.334640   Val_Acc:87.500%   Test_Acc:90.940%\n",
      "Epochs: 3800   Loss:0.228964   Val_Acc:93.750%   Test_Acc:90.710%\n",
      "Epochs: 3900   Loss:0.431616   Val_Acc:87.500%   Test_Acc:91.000%\n",
      "Epochs: 4000   Loss:0.185619   Val_Acc:100.000%   Test_Acc:90.760%\n",
      "Epochs: 4100   Loss:0.343390   Val_Acc:93.750%   Test_Acc:91.250%\n",
      "Epochs: 4200   Loss:0.209934   Val_Acc:93.750%   Test_Acc:91.360%\n",
      "Epochs: 4300   Loss:0.270434   Val_Acc:87.500%   Test_Acc:91.140%\n",
      "Epochs: 4400   Loss:0.097717   Val_Acc:100.000%   Test_Acc:91.440%\n",
      "Epochs: 4500   Loss:0.395235   Val_Acc:87.500%   Test_Acc:91.750%\n",
      "Epochs: 4600   Loss:0.192148   Val_Acc:100.000%   Test_Acc:91.680%\n",
      "Epochs: 4700   Loss:0.164293   Val_Acc:100.000%   Test_Acc:91.960%\n",
      "Epochs: 4800   Loss:0.149893   Val_Acc:100.000%   Test_Acc:91.990%\n",
      "Epochs: 4900   Loss:0.191126   Val_Acc:100.000%   Test_Acc:92.170%\n",
      "Epochs: 5000   Loss:0.296025   Val_Acc:93.750%   Test_Acc:92.180%\n",
      "Epochs: 5100   Loss:0.054706   Val_Acc:100.000%   Test_Acc:92.410%\n",
      "Epochs: 5200   Loss:0.106259   Val_Acc:100.000%   Test_Acc:92.040%\n",
      "Epochs: 5300   Loss:0.353156   Val_Acc:87.500%   Test_Acc:92.310%\n",
      "Epochs: 5400   Loss:0.133886   Val_Acc:100.000%   Test_Acc:92.390%\n",
      "Epochs: 5500   Loss:0.179785   Val_Acc:93.750%   Test_Acc:92.680%\n",
      "Epochs: 5600   Loss:0.587953   Val_Acc:81.250%   Test_Acc:92.320%\n",
      "Epochs: 5700   Loss:0.274379   Val_Acc:87.500%   Test_Acc:92.370%\n",
      "Epochs: 5800   Loss:0.085396   Val_Acc:100.000%   Test_Acc:93.130%\n",
      "Epochs: 5900   Loss:0.072848   Val_Acc:100.000%   Test_Acc:93.200%\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    idx = np.random.randint(0, x_train.shape[0], size=BATCH_SIZE)\n",
    "\n",
    "    x_batch = x_train[idx]\n",
    "    y_batch = y_train[idx]\n",
    "\n",
    "    sess.run(train_op, feed_dict={ x: x_batch, y: y_batch })\n",
    "    LOSS, ACC = sess.run([loss, accuracy], feed_dict={ x: x_batch, y: y_batch })\n",
    "\n",
    "    if i%100 == 0:\n",
    "        TEST_ACC = 0\n",
    "        count = 0\n",
    "        j=0\n",
    "        while j<x_test.shape[0] :\n",
    "            TEST_ACC += sess.run(accuracy, feed_dict={ \n",
    "                            x: x_test[j:min(j+BATCH_SIZE, x_test.shape[0])], \n",
    "                            y: y_test[j:min(j+BATCH_SIZE, x_test.shape[0])]\n",
    "                                                    })\n",
    "\n",
    "            j = j+BATCH_SIZE\n",
    "            count += 1\n",
    "\n",
    "        print(\"Epochs: {:4d}   Loss:{:.6f}   Val_Acc:{:.3f}%   Test_Acc:{:.3f}%\".format(i, LOSS, ACC*100, 100*TEST_ACC/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reinforcment",
   "language": "python",
   "name": "reinforcment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
